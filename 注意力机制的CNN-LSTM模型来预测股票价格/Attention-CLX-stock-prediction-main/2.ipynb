{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>5.69</td>\n",
       "      <td>5.97</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.63</td>\n",
       "      <td>4224852.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>5.30</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.07</td>\n",
       "      <td>5.07</td>\n",
       "      <td>4050377.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>4.87</td>\n",
       "      <td>5.14</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.08</td>\n",
       "      <td>2763751.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>5.06</td>\n",
       "      <td>5.19</td>\n",
       "      <td>4.95</td>\n",
       "      <td>5.18</td>\n",
       "      <td>2198327.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-10</th>\n",
       "      <td>5.25</td>\n",
       "      <td>5.29</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1915221.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-11</th>\n",
       "      <td>3.08</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.10</td>\n",
       "      <td>550569.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-14</th>\n",
       "      <td>3.08</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.09</td>\n",
       "      <td>489277.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-15</th>\n",
       "      <td>3.09</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.03</td>\n",
       "      <td>886628.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-16</th>\n",
       "      <td>3.04</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.07</td>\n",
       "      <td>668104.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-17</th>\n",
       "      <td>3.08</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.06</td>\n",
       "      <td>609118.280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3681 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            open  high   low  close       amount\n",
       "trade_date                                      \n",
       "2007-01-04  5.69  5.97  5.37   5.63  4224852.614\n",
       "2007-01-05  5.30  5.34  5.07   5.07  4050377.943\n",
       "2007-01-08  4.87  5.14  4.83   5.08  2763751.983\n",
       "2007-01-09  5.06  5.19  4.95   5.18  2198327.249\n",
       "2007-01-10  5.25  5.29  5.05   5.10  1915221.182\n",
       "...          ...   ...   ...    ...          ...\n",
       "2022-03-11  3.08  3.11  3.06   3.10   550569.534\n",
       "2022-03-14  3.08  3.12  3.07   3.09   489277.432\n",
       "2022-03-15  3.09  3.09  3.02   3.03   886628.898\n",
       "2022-03-16  3.04  3.08  3.02   3.07   668104.914\n",
       "2022-03-17  3.08  3.09  3.05   3.06   609118.280\n",
       "\n",
       "[3681 rows x 5 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional\n",
    "from keras.optimizers import adam_v2\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from numpy.random import seed\n",
    "from utils import *\n",
    "from model import *\n",
    "\n",
    "\n",
    "# GPU\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    tf.config.set_visible_devices([gpus[0]], \"GPU\")\n",
    "\n",
    "seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "n_timestamp = 10\n",
    "n_epochs = 50\n",
    "# ====================================\n",
    "#      model type：\n",
    "#            1. single-layer LSTM\n",
    "#            2. multi-layer LSTM\n",
    "#            3. bidirectional LSTM\n",
    "# ====================================\n",
    "\n",
    "\n",
    "yuan_data = pd.read_csv('601988.SH.csv')  \n",
    "yuan_data.index = pd.to_datetime(yuan_data['trade_date'], format='%Y%m%d') \n",
    "yuan_data = yuan_data.loc[:, ['open', 'high', 'low', 'close', 'amount']]\n",
    "yuan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('ARIMA_residuals1.csv')\n",
    "data.index = pd.to_datetime(data['trade_date'])\n",
    "data = data.drop('trade_date', axis=1)\n",
    "# data = pd.merge(data, yuan_data, on='trade_date') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Lt = pd.read_csv('ARIMA.csv')\n",
    "idx = 3500\n",
    "training_set = data.iloc[1:idx, :]\n",
    "test_set = data.iloc[idx:, :]\n",
    "yuan_training_set = yuan_data.iloc[1:idx, :]\n",
    "yuan_test_set = yuan_data.iloc[idx:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_yuan = [x for x in yuan_training_set['close']]\n",
    "predictions_yuan = list()\n",
    "for t in range(len(yuan_test_set)):\n",
    "    model1 = sm.tsa.ARIMA(history_yuan, order=(2, 1, 0))\n",
    "    model_fit = model1.fit()\n",
    "    yhat = model_fit.forecast()\n",
    "    predictions_yuan.append(yhat[0])\n",
    "    obs = yuan_test_set.iloc[t, 3]\n",
    "    history_yuan.append(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [x for x in training_set.iloc[:,0]]\n",
    "predictions = list()\n",
    "for t in range(len(test_set)):\n",
    "    model1 = sm.tsa.ARIMA(history, order=(2, 1, 0))\n",
    "    model_fit = model1.fit()\n",
    "    yhat = model_fit.forecast()\n",
    "    predictions.append(yhat[0])\n",
    "    obs = test_set.iloc[t, 0]\n",
    "    history.append(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade_date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-21</th>\n",
       "      <td>3.058920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-22</th>\n",
       "      <td>0.893830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23</th>\n",
       "      <td>-2.185780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-24</th>\n",
       "      <td>-0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-25</th>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-11</th>\n",
       "      <td>-0.023977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-14</th>\n",
       "      <td>-0.019226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-15</th>\n",
       "      <td>-0.002940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-16</th>\n",
       "      <td>0.002138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-17</th>\n",
       "      <td>-0.015439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "trade_date          \n",
       "2021-06-21  3.058920\n",
       "2021-06-22  0.893830\n",
       "2021-06-23 -2.185780\n",
       "2021-06-24 -0.004300\n",
       "2021-06-25  0.002812\n",
       "...              ...\n",
       "2022-03-11 -0.023977\n",
       "2022-03-14 -0.019226\n",
       "2022-03-15 -0.002940\n",
       "2022-03-16  0.002138\n",
       "2022-03-17 -0.015439\n",
       "\n",
       "[181 rows x 1 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00027108880712126067"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(list(yuan_test_set['close']),predictions_yuan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08263848988636188"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(list(test_set.iloc[:,0]),predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang xiaoqing\\AppData\\Local\\Temp\\ipykernel_25316\\2457178840.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  yuan_test_set.loc[:,'close']=predictions_yuan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-21</th>\n",
       "      <td>3.06</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.061432</td>\n",
       "      <td>359751.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-22</th>\n",
       "      <td>3.07</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.071164</td>\n",
       "      <td>285873.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23</th>\n",
       "      <td>3.07</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.069248</td>\n",
       "      <td>268733.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-24</th>\n",
       "      <td>3.07</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>252945.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-25</th>\n",
       "      <td>3.08</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>390793.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-11</th>\n",
       "      <td>3.08</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.081495</td>\n",
       "      <td>550569.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-14</th>\n",
       "      <td>3.08</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.099315</td>\n",
       "      <td>489277.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-15</th>\n",
       "      <td>3.09</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.088847</td>\n",
       "      <td>886628.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-16</th>\n",
       "      <td>3.04</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.032802</td>\n",
       "      <td>668104.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-17</th>\n",
       "      <td>3.08</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.073117</td>\n",
       "      <td>609118.280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            open  high   low     close      amount\n",
       "trade_date                                        \n",
       "2021-06-21  3.06  3.08  3.06  3.061432  359751.317\n",
       "2021-06-22  3.07  3.08  3.06  3.071164  285873.151\n",
       "2021-06-23  3.07  3.08  3.06  3.069248  268733.070\n",
       "2021-06-24  3.07  3.08  3.06  3.070000  252945.198\n",
       "2021-06-25  3.08  3.10  3.07  3.070000  390793.156\n",
       "...          ...   ...   ...       ...         ...\n",
       "2022-03-11  3.08  3.11  3.06  3.081495  550569.534\n",
       "2022-03-14  3.08  3.12  3.07  3.099315  489277.432\n",
       "2022-03-15  3.09  3.09  3.02  3.088847  886628.898\n",
       "2022-03-16  3.04  3.08  3.02  3.032802  668104.914\n",
       "2022-03-17  3.08  3.09  3.05  3.073117  609118.280\n",
       "\n",
       "[181 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yuan_test_set.loc[:,'close']=predictions_yuan\n",
    "yuan_test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tang xiaoqing\\AppData\\Local\\Temp\\ipykernel_25316\\2405024620.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set.iloc[:,0]=predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trade_date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-21</th>\n",
       "      <td>3.058920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-22</th>\n",
       "      <td>0.893830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23</th>\n",
       "      <td>-2.185780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-24</th>\n",
       "      <td>-0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-25</th>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-11</th>\n",
       "      <td>-0.023977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-14</th>\n",
       "      <td>-0.019226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-15</th>\n",
       "      <td>-0.002940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-16</th>\n",
       "      <td>0.002138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-17</th>\n",
       "      <td>-0.015439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "trade_date          \n",
       "2021-06-21  3.058920\n",
       "2021-06-22  0.893830\n",
       "2021-06-23 -2.185780\n",
       "2021-06-24 -0.004300\n",
       "2021-06-25  0.002812\n",
       "...              ...\n",
       "2022-03-11 -0.023977\n",
       "2022-03-14 -0.019226\n",
       "2022-03-15 -0.002940\n",
       "2022-03-16  0.002138\n",
       "2022-03-17 -0.015439\n",
       "\n",
       "[181 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.iloc[:,0]=predictions\n",
    "test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "yuan_sc = MinMaxScaler(feature_range=(0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "testing_set_scaled = sc.fit_transform(test_set)\n",
    "yuan_training_set_scaled = yuan_sc.fit_transform(yuan_training_set)\n",
    "yuan_testing_set_scaled = yuan_sc.fit_transform(yuan_test_set)\n",
    "\n",
    "X_train, y_train = data_split(training_set_scaled, n_timestamp)\n",
    "yuan_X_train, yuan_y_train = data_split(yuan_training_set_scaled, n_timestamp)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "yuan_X_train = yuan_X_train.reshape(yuan_X_train.shape[0], yuan_X_train.shape[1], 5)\n",
    "\n",
    "X_test, y_test = data_split(testing_set_scaled, n_timestamp)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "yuan_X_test, yuan_y_test = data_split(yuan_testing_set_scaled, n_timestamp)\n",
    "yuna_X_test = yuan_X_test.reshape(yuan_X_test.shape[0], yuan_X_test.shape[1], 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3489, 10, 1)\n",
      "(3489, 10, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "y_train.shape\n",
    "print(yuan_X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 3489, 16)          32        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3489, 16)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100)               26800     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 26,933\n",
      "Trainable params: 26,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 3489, 64)          384       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3489, 64)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 100)               46000     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 46,889\n",
      "Trainable params: 46,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3489, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3489, 1), dtype=tf.float32, name='conv1d_2_input'), name='conv1d_2_input', description=\"created by layer 'conv1d_2_input'\"), but it was called on an input with incompatible shape (None, 10, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3489, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3489, 1), dtype=tf.float32, name='conv1d_2_input'), name='conv1d_2_input', description=\"created by layer 'conv1d_2_input'\"), but it was called on an input with incompatible shape (None, 10, 1).\n",
      "108/110 [============================>.] - ETA: 0s - loss: 0.0137WARNING:tensorflow:Model was constructed with shape (None, 3489, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3489, 1), dtype=tf.float32, name='conv1d_2_input'), name='conv1d_2_input', description=\"created by layer 'conv1d_2_input'\"), but it was called on an input with incompatible shape (None, 10, 1).\n",
      "110/110 [==============================] - 4s 10ms/step - loss: 0.0136 - val_loss: 0.0022\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0066\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0095\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0059\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0082\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0120\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0110\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0084\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0147\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0131\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0047 - val_loss: 0.0108\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.0046 - val_loss: 0.0072\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0117\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0081\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0112\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0142\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0116\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0046 - val_loss: 0.0147\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0165\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0107\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0150\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0106\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0108\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0135\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0139\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0097\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0118\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0125\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0139\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0095\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0137\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0151\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0136\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0149\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0126\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0113\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0137\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0118\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0127\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0098\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0135\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0112\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0152\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0119\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3489, 5) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3489, 5), dtype=tf.float32, name='conv1d_3_input'), name='conv1d_3_input', description=\"created by layer 'conv1d_3_input'\"), but it was called on an input with incompatible shape (None, 10, 5).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3489, 5) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3489, 5), dtype=tf.float32, name='conv1d_3_input'), name='conv1d_3_input', description=\"created by layer 'conv1d_3_input'\"), but it was called on an input with incompatible shape (None, 10, 5).\n",
      "106/110 [===========================>..] - ETA: 0s - loss: 0.0579WARNING:tensorflow:Model was constructed with shape (None, 3489, 5) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3489, 5), dtype=tf.float32, name='conv1d_3_input'), name='conv1d_3_input', description=\"created by layer 'conv1d_3_input'\"), but it was called on an input with incompatible shape (None, 10, 5).\n",
      "110/110 [==============================] - 4s 11ms/step - loss: 0.0571 - val_loss: 0.0754\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0765\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0804\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0826\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0787\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0840\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0792\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0758\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0790\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0848\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0839\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0904\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0783\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0808\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0796\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0837\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0785\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0886\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0245 - val_loss: 0.0862\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0796\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0796\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0805\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0814\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0813\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0783\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0750\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0779\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0244 - val_loss: 0.0756\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0828\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0753\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0244 - val_loss: 0.0804\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0812\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0851\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0864\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0820\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0797\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0787\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0805\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0799\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0755\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0244 - val_loss: 0.0766\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0863\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0851\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0244 - val_loss: 0.0751\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0828\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0806\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0838\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0850\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0243 - val_loss: 0.0761\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0242 - val_loss: 0.0822\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model ,yuan_model= cnn_lstm_model(X_train,yuan_X_train)\n",
    "model.summary() \n",
    "yuan_model.summary()\n",
    "adam = adam_v2.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=adam, loss='mse') \n",
    "yuan_model.compile(optimizer=adam, loss='mse') \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=n_epochs,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    validation_freq=1)\n",
    "yuan_history = yuan_model.fit(yuan_X_train, yuan_y_train,\n",
    "                              batch_size=32,\n",
    "                              epochs=n_epochs,\n",
    "                              validation_data=(yuan_X_test, yuan_y_test),\n",
    "                              validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011091978675685822"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08072994038462639"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(yuan_history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 50)                10400     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 50)                11200     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 11,455\n",
      "Trainable params: 11,455\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "110/110 [==============================] - 4s 6ms/step - loss: 0.0153 - val_loss: 0.0229\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.0246\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.0252\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0048 - val_loss: 0.0244\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0238\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.0244\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.0231\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0237\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.0240\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0242\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0048 - val_loss: 0.0267\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0283\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.0252\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.0274\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0271\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0265\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0251\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0272\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0260\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0270\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0284\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0270\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0287\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0288\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0320\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0275\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0310\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0275\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0271\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0304\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0325\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0292\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0297\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0303\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0313\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0284\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0299\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0324\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0312\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0303\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0299\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0294\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0307\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0044 - val_loss: 0.0289\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0310\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0283\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0305\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0298\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0312\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0297\n",
      "Epoch 1/50\n",
      "110/110 [==============================] - 2s 6ms/step - loss: 0.0095 - val_loss: 0.0138\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 5.7920e-04 - val_loss: 0.0092\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 3.6633e-04 - val_loss: 0.0088\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 3.5023e-04 - val_loss: 0.0086\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 3.2114e-04 - val_loss: 0.0085\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 3.2822e-04 - val_loss: 0.0085\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 3.1352e-04 - val_loss: 0.0084\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 3.0843e-04 - val_loss: 0.0083\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 2.9439e-04 - val_loss: 0.0081\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.9486e-04 - val_loss: 0.0079\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 2.9419e-04 - val_loss: 0.0078\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.8969e-04 - val_loss: 0.0079\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 2.8793e-04 - val_loss: 0.0078\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.9653e-04 - val_loss: 0.0077\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.7427e-04 - val_loss: 0.0077\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.8841e-04 - val_loss: 0.0076\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.8285e-04 - val_loss: 0.0077\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.8536e-04 - val_loss: 0.0076\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.8862e-04 - val_loss: 0.0078\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.7745e-04 - val_loss: 0.0075\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.6690e-04 - val_loss: 0.0080\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.7676e-04 - val_loss: 0.0077\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.8087e-04 - val_loss: 0.0076\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.7313e-04 - val_loss: 0.0078\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.7860e-04 - val_loss: 0.0078\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.7535e-04 - val_loss: 0.0075\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.8123e-04 - val_loss: 0.0077\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.7553e-04 - val_loss: 0.0075\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.7191e-04 - val_loss: 0.0077\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.6621e-04 - val_loss: 0.0075\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.7326e-04 - val_loss: 0.0076\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.6490e-04 - val_loss: 0.0076\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 2.7473e-04 - val_loss: 0.0074\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.6561e-04 - val_loss: 0.0077\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.7401e-04 - val_loss: 0.0077\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.6738e-04 - val_loss: 0.0078\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.6974e-04 - val_loss: 0.0078\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.7064e-04 - val_loss: 0.0077\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.8024e-04 - val_loss: 0.0077\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.6657e-04 - val_loss: 0.0081\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 2.8711e-04 - val_loss: 0.0081\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 2.7503e-04 - val_loss: 0.0079\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 2.6762e-04 - val_loss: 0.0076\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 2.7932e-04 - val_loss: 0.0077\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 2.7114e-04 - val_loss: 0.0078\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 2.5941e-04 - val_loss: 0.0078\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 2.6360e-04 - val_loss: 0.0077\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 0s 4ms/step - loss: 2.6406e-04 - val_loss: 0.0085\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 2.7248e-04 - val_loss: 0.0078\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 0s 5ms/step - loss: 2.7566e-04 - val_loss: 0.0079\n"
     ]
    }
   ],
   "source": [
    "model ,yuan_model= lstm(1,X_train,yuan_X_train)\n",
    "model.summary() \n",
    "yuan_model.summary()\n",
    "adam = adam_v2.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=adam, loss='mse') \n",
    "yuan_model.compile(optimizer=adam, loss='mse') \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=n_epochs,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    validation_freq=1)\n",
    "yuan_history = yuan_model.fit(yuan_X_train, yuan_y_train,\n",
    "                              batch_size=32,\n",
    "                              epochs=n_epochs,\n",
    "                              validation_data=(yuan_X_test, yuan_y_test),\n",
    "                              validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027992794811725615"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008001245632767677"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(yuan_history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_6 (Bidirection (None, 100)               20800     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 20,901\n",
      "Trainable params: 20,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_7 (Bidirection (None, 100)               22400     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 22,905\n",
      "Trainable params: 22,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "110/110 [==============================] - 4s 11ms/step - loss: 0.0112 - val_loss: 0.0232\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0241\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0259\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0049 - val_loss: 0.0235\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0235\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0246\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0231\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0235\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0236\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0244\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0048 - val_loss: 0.0255\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0255\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0247\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0276\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0266\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0258\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0245\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0263\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0249\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0264\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0275\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0264\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0265\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0278\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.0046 - val_loss: 0.0291\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0261\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0285\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0265\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0047 - val_loss: 0.0264\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0277\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 1s 11ms/step - loss: 0.0047 - val_loss: 0.0279\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0261\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0269\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0275\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0281\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0263\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0280\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0287\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0282\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0292\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.0046 - val_loss: 0.0275\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 1s 10ms/step - loss: 0.0045 - val_loss: 0.0270\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0283\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0274\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0280\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0267\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0289\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0284\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0045 - val_loss: 0.0292\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.0046 - val_loss: 0.0280\n",
      "Epoch 1/50\n",
      "110/110 [==============================] - 4s 10ms/step - loss: 0.0022 - val_loss: 0.0121\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 5.3092e-04 - val_loss: 0.0095\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 3.5860e-04 - val_loss: 0.0084\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 3.3953e-04 - val_loss: 0.0084\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 3.2871e-04 - val_loss: 0.0085\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 3.4438e-04 - val_loss: 0.0088\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 3.1632e-04 - val_loss: 0.0082\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 3.0595e-04 - val_loss: 0.0085\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 3.0279e-04 - val_loss: 0.0080\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.9688e-04 - val_loss: 0.0079\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.8583e-04 - val_loss: 0.0077\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.8426e-04 - val_loss: 0.0079\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.8463e-04 - val_loss: 0.0079\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 3.1637e-04 - val_loss: 0.0080\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6596e-04 - val_loss: 0.0080\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.7380e-04 - val_loss: 0.0079\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.7796e-04 - val_loss: 0.0078\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.8608e-04 - val_loss: 0.0080\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 3.0926e-04 - val_loss: 0.0084\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.8345e-04 - val_loss: 0.0079\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6123e-04 - val_loss: 0.0081\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.7752e-04 - val_loss: 0.0080\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.7311e-04 - val_loss: 0.0079\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6736e-04 - val_loss: 0.0082\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.7192e-04 - val_loss: 0.0081\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.7705e-04 - val_loss: 0.0076\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.8005e-04 - val_loss: 0.0080\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.8114e-04 - val_loss: 0.0081\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.8382e-04 - val_loss: 0.0084\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6768e-04 - val_loss: 0.0080\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6764e-04 - val_loss: 0.0079\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6065e-04 - val_loss: 0.0079\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.7169e-04 - val_loss: 0.0077\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6430e-04 - val_loss: 0.0082\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.8321e-04 - val_loss: 0.0084\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6894e-04 - val_loss: 0.0084\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6999e-04 - val_loss: 0.0084\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6792e-04 - val_loss: 0.0084\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.8512e-04 - val_loss: 0.0082\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6881e-04 - val_loss: 0.0087\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.8963e-04 - val_loss: 0.0089\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.7782e-04 - val_loss: 0.0081\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6321e-04 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.7271e-04 - val_loss: 0.0079\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6938e-04 - val_loss: 0.0083\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6491e-04 - val_loss: 0.0083\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6356e-04 - val_loss: 0.0080\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.5906e-04 - val_loss: 0.0086\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.6311e-04 - val_loss: 0.0080\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 2.7417e-04 - val_loss: 0.0086\n"
     ]
    }
   ],
   "source": [
    "model ,yuan_model= lstm(3,X_train,yuan_X_train)\n",
    "model.summary() \n",
    "yuan_model.summary()\n",
    "adam = adam_v2.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=adam, loss='mse') \n",
    "yuan_model.compile(optimizer=adam, loss='mse') \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=n_epochs,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    validation_freq=1)\n",
    "yuan_history = yuan_model.fit(yuan_X_train, yuan_y_train,\n",
    "                              batch_size=32,\n",
    "                              epochs=n_epochs,\n",
    "                              validation_data=(yuan_X_test, yuan_y_test),\n",
    "                              validation_freq=1)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2236836740374565"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00850442805327475"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(yuan_history.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cd6af004486e18d8cd1b1dc71eb6e14b35da0a003c4531af785de1b844902cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
