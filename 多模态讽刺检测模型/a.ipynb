{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from transformers import RobertaTokenizer,RobertaModel\n",
    "import LoadData\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os\n",
    "WORKING_PATH=\"C:/Users/tang xiaoqing/Desktop/深度学习/注意力/pytorch-multimodal_sarcasm_detection-main/\"\n",
    "def load_data():\n",
    "    data_set=dict()\n",
    "    for dataset in [\"train\"]:\n",
    "        file=open(os.path.join(WORKING_PATH,\"text_data/\",dataset+\".txt\"),\"rb\")\n",
    "        for line in file:\n",
    "            content=eval(line)\n",
    "            image=content[0]\n",
    "            sentence=content[1]\n",
    "            group=content[2]\n",
    "            if os.path.isfile(os.path.join(WORKING_PATH,\"image_data/\",image+\".jpg\")):\n",
    "                data_set[int(image)]={\"text\":sentence,\"group\":group}\n",
    "    for dataset in [\"test\",\"valid\"]:\n",
    "        file=open(os.path.join(WORKING_PATH,\"text_data/\",dataset+\".txt\"),\"rb\")\n",
    "        for line in file:\n",
    "            content=eval(line)\n",
    "            image=content[0]\n",
    "            sentence=content[1]\n",
    "            group=content[3] #2\n",
    "            if os.path.isfile(os.path.join(WORKING_PATH,\"image_data/\",image+\".jpg\")):\n",
    "                data_set[int(image)]={\"text\":sentence,\"group\":group}\n",
    "    data=open('multilabel_database/img_to_five_words.txt')\n",
    "    for i in data:\n",
    "        i=eval(i)\n",
    "        image=i[0]\n",
    "        token=i[1:]\n",
    "        if os.path.isfile(os.path.join(WORKING_PATH,\"image_data/\",image+\".jpg\")):\n",
    "                data_set[int(image)]['token']=token\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "train_index=np.random.choice(range(len(data_set)),size=20000,replace=False)\n",
    "train_set=[]\n",
    "test_set=[]\n",
    "for i in train_index:\n",
    "    train_set.append(data_set[list(data_set.keys())[i]])\n",
    "for i in range(len(data_set)):\n",
    "    if i not in train_index:\n",
    "        test_set.append(data_set[list(data_set.keys())[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=train_set[:5000]\n",
    "test_set=test_set[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train=[list(data_set.keys())[i]for i in train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test=[list(data_set.keys())[i] for i in range(len(data_set)) if i not in train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train=[]\n",
    "token_train=[]\n",
    "labels_train=[]\n",
    "for i in train_set:\n",
    "    text_train.append(i['text'])\n",
    "    token_train.append(i['token'])\n",
    "    labels_train.append(i['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test=[]\n",
    "token_test=[]\n",
    "labels_test=[]\n",
    "for i in test_set:\n",
    "    text_test.append(i['text'])\n",
    "    token_test.append(i['token'])\n",
    "    labels_test.append(i['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Softmax\n",
    "def INF(B,H,W):\n",
    "    '''\n",
    "    生成(B*W,H,H)大小的对角线为inf的三维矩阵\n",
    "    Parameters\n",
    "    ----------\n",
    "    B: batch\n",
    "    H: height\n",
    "    W: width\n",
    "    '''\n",
    "    return -torch.diag(torch.tensor(float(\"inf\")).repeat(H),0).unsqueeze(0).repeat(B*W,1,1).to(device)\n",
    "\n",
    "\n",
    "class CC_module(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_dim, device):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_dim : int\n",
    "            channels of input\n",
    "        '''\n",
    "        super(CC_module, self).__init__()\n",
    "        self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//2, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//2, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        self.softmax = Softmax(dim=3)\n",
    "        self.INF = INF\n",
    "        self.gamma = nn.Parameter(torch.zeros(1)).to(device)\n",
    "        self.device = device\n",
    "          \n",
    "    def forward(self, x):\n",
    "\n",
    "        m_batchsize, _, height, width = x.size()\n",
    "        \n",
    "        proj_query = self.query_conv(x) #size = (b,c2,h,w), c1 = in_dim, c2 = c1 // split\n",
    "        \n",
    "        #size = (b*w, h, c2)\n",
    "        proj_query_H = proj_query.permute(0,3,1,2).contiguous().view(m_batchsize*width,-1,height).permute(0, 2, 1) \n",
    "        \n",
    "        #size = (b*h, w, c2)\n",
    "        proj_query_W = proj_query.permute(0,2,1,3).contiguous().view(m_batchsize*height,-1,width).permute(0, 2, 1)\n",
    "        \n",
    "        proj_key = self.key_conv(x) #size = (b,c2,h,w)\n",
    "        \n",
    "        proj_key_H = proj_key.permute(0,3,1,2).contiguous().view(m_batchsize*width,-1,height) \n",
    "        proj_key_W = proj_key.permute(0,2,1,3).contiguous().view(m_batchsize*height,-1,width) #size = (b*w,c2,h)\n",
    "        \n",
    "        proj_value = self.value_conv(x) #size = (b,c1,h,w)\n",
    "        proj_value_H = proj_value.permute(0,3,1,2).contiguous().view(m_batchsize*width,-1,height) #size = (b*w,c1,h)\n",
    "        proj_value_W = proj_value.permute(0,2,1,3).contiguous().view(m_batchsize*height,-1,width) #size = (b*h,c1,w)\n",
    "        \n",
    "        #size = (b*w, h,h) ,其中[:,i,j]表示Q所有W的第Hi行的所有通道值与K上所有W的第Hj列的所有通道值的向量乘积 \n",
    "        energy_H = torch.bmm(proj_query_H, proj_key_H).to(device)\n",
    "        \n",
    "        #size = (b,h,w,h) #这里为什么加 INF并没有理解\n",
    "        energy_H = (energy_H + self.INF(m_batchsize, height, width)).view(m_batchsize,width,height,height).permute(0,2,1,3)\n",
    "        \n",
    "        #size = (b*h,w,w),其中[:,i,j]表示Q所有H的第Wi行的所有通道值与K上所有H的第Wj列的所有通道值的向量乘积\n",
    "        energy_W = torch.bmm(proj_query_W, proj_key_W)\n",
    "        energy_W = energy_W.view(m_batchsize,height,width,width) #size = (b,h,w,w)\n",
    "        \n",
    "        concate = self.softmax(torch.cat([energy_H, energy_W], 3)) #size = (b,h,w,h+w) #softmax归一化\n",
    "        #concate = concate * (concate>torch.mean(concate,dim=3,keepdim=True)).float()\n",
    "        att_H = concate[:,:,:,0:height].permute(0,2,1,3).contiguous().view(m_batchsize*width,height,height) #size = (b*w,h,h)\n",
    "        #print(concate)\n",
    "        #print(att_H) \n",
    "        att_W = concate[:,:,:,height:height+width].contiguous().view(m_batchsize*height,width,width) #size = (b*h,w,w)\n",
    "        \n",
    "        #size = (b*w,c1,h) #[:,i,j]表示V所有W的第Ci行通道上的所有H 与att_H的所有W的第Hj列的h权重的乘积  \n",
    "        out_H = torch.bmm(proj_value_H, att_H.permute(0, 2, 1))\n",
    "        out_H = out_H.view(m_batchsize,width,-1,height).permute(0,2,3,1)  #size = (b,c1,h,w)\n",
    "        \n",
    "        #size = (b*h,c1,w) #[:,i,j]表示V所有H的第Ci行通道上的所有W 与att_W的所有H的第Wj列的W权重的乘积  \n",
    "        out_W = torch.bmm(proj_value_W, att_W.permute(0, 2, 1))\n",
    "        out_W = out_W.view(m_batchsize,height,-1,width).permute(0,2,1,3) #size = (b,c1,h,w)\n",
    "        #print(out_H.size(),out_W.size())\n",
    "        \n",
    "        return self.gamma*(out_H + out_W) + x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channel):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.Cam = ChannelAttentionModul(in_channel=in_channel)  # 通道注意力模块\n",
    "        self.Sam = SpatialAttentionModul(in_channel=in_channel)  # 空间注意力模块\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Cam(x)\n",
    "        x = self.Sam(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ChannelAttentionModul(nn.Module):  # 通道注意力模块\n",
    "    def __init__(self, in_channel, r=0.5):  # channel为输入的维度, r为全连接层缩放比例->控制中间层个数\n",
    "        super(ChannelAttentionModul, self).__init__()\n",
    "        # 全局最大池化\n",
    "        self.MaxPool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc_MaxPool = nn.Sequential(\n",
    "            nn.Linear(in_channel, int(in_channel * r)),  # int(channel * r)取整数, 中间层神经元数至少为1, 如有必要可设为向上取整\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(in_channel * r), in_channel),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        # 全局均值池化\n",
    "        self.AvgPool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.fc_AvgPool = nn.Sequential(\n",
    "            nn.Linear(in_channel, int(in_channel * r)),  # int(channel * r)取整数, 中间层神经元数至少为1, 如有必要可设为向上取整\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(in_channel * r), in_channel),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        # 激活函数\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1.最大池化分支\n",
    "        max_branch = self.MaxPool(x)\n",
    "        # 送入MLP全连接神经网络, 得到权重\n",
    "        max_in = max_branch.view(max_branch.size(0), -1)\n",
    "        max_weight = self.fc_MaxPool(max_in)\n",
    "\n",
    "        # 2.全局池化分支\n",
    "        avg_branch = self.AvgPool(x)\n",
    "        # 送入MLP全连接神经网络, 得到权重\n",
    "        avg_in = avg_branch.view(avg_branch.size(0), -1)\n",
    "        avg_weight = self.fc_AvgPool(avg_in)\n",
    "\n",
    "        # MaxPool + AvgPool 激活后得到权重weight\n",
    "        weight = max_weight + avg_weight\n",
    "        weight = self.sigmoid(weight)\n",
    "\n",
    "        # 将维度为b, c的weight, reshape成b, c, 1, 1 与 输入x 相乘\n",
    "        h, w = weight.shape\n",
    "        # 通道注意力Mc\n",
    "        Mc = torch.reshape(weight, (h, w, 1, 1))\n",
    "\n",
    "        # 乘积获得结果\n",
    "        x = Mc * x\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpatialAttentionModul(nn.Module):  # 空间注意力模块\n",
    "    def __init__(self, in_channel):\n",
    "        super(SpatialAttentionModul, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, 7, padding=3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x维度为 [N, C, H, W] 沿着维度C进行操作, 所以dim=1, 结果为[N, H, W]\n",
    "        MaxPool = torch.max(x, dim=1).values  # torch.max 返回的是索引和value， 要用.values去访问值才行！\n",
    "        AvgPool = torch.mean(x, dim=1)\n",
    "\n",
    "        # 增加维度, 变成 [N, 1, H, W]\n",
    "        MaxPool = torch.unsqueeze(MaxPool, dim=1)\n",
    "        AvgPool = torch.unsqueeze(AvgPool, dim=1)\n",
    "\n",
    "        # 维度拼接 [N, 2, H, W]\n",
    "        x_cat = torch.cat((MaxPool, AvgPool), dim=1)  # 获得特征图\n",
    "\n",
    "        # 卷积操作得到空间注意力结果\n",
    "        x_out = self.conv(x_cat)\n",
    "        Ms = self.sigmoid(x_out)\n",
    "\n",
    "        # 与原图通道进行乘积\n",
    "        x = Ms * x\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch as pt\n",
    "import torch.nn.functional as F\n",
    "class MLP(pt.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.fc1 = pt.nn.Linear(6*512,512)\n",
    "        self.fc2 = pt.nn.Linear(512,128)\n",
    "        self.fc3 = pt.nn.Linear(128,2)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "    def forward(self,din):\n",
    "        din = din.view(-1,6*512)\n",
    "        dout = pt.nn.functional.relu(self.fc1(din))\n",
    "        dout = pt.nn.functional.relu(self.fc2(dout))\n",
    "        return self.softmax(self.fc3(dout))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1, preprocess = clip.load('ViT-B/16',device=\"cuda\") \n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at model/roberta-base/ were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_file = 'model/vocab.json'\n",
    "merges_file = 'model/merges.txt'\n",
    "tokenizer = RobertaTokenizer(vocab_file, merges_file)\n",
    "roberta = RobertaModel.from_pretrained('model/roberta-base/')\n",
    "roberta.pooler.dense=nn.Linear(in_features=768,out_features=512,bias=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "device = torch.device('cuda:0' if torch.cuda.device_count()==1 else 'cpu')\n",
    "class Model(pt.nn.Module):\n",
    "    def __init__(self,indim,device,outdim):\n",
    "        super(Model,self).__init__()\n",
    "        self.model1=roberta.to(device)\n",
    "        self.model2=model1.to(device)\n",
    "        self.attention1=CC_module(in_dim=indim,device=device).to(device)\n",
    "        self.attention2=CBAM(in_channel=indim).to(device)\n",
    "        self.attention3=CBAM(in_channel=outdim).to(device)\n",
    "        self.model3=MLP().to(device)\n",
    "    def forward(self,text,token,img,num,count):\n",
    "        encoded_input=tokenizer(text, return_tensors='pt',padding=True).to(device)\n",
    "        text_list=self.model1(**encoded_input)[1]\n",
    "        token_list=[]\n",
    "        for i in token:\n",
    "            text1 = clip.tokenize(i).to(device)\n",
    "            text_features = self.model2.encode_text(text1)\n",
    "            token_list.append(text_features)\n",
    "        token_list=torch.tensor([item.cpu().detach().numpy()for item in token_list]).to(device)\n",
    "        token_list=torch.max(token_list,dim=1)\n",
    "        token_list=token_list.values\n",
    "        image_list=[]\n",
    "        for i in range(count*num,(count+1)*num):\n",
    "            b=os.path.join(WORKING_PATH,\"image_data/\",str(img[i])+\".jpg\")\n",
    "            if os.path.isfile(b):\n",
    "                a=Image.open(b)\n",
    "                image = preprocess(a).unsqueeze(0).to(device)\n",
    "                image_features = self.model2.encode_image(image)\n",
    "                image_list.append(image_features)\n",
    "                a.close()\n",
    "        image_list=torch.tensor([item.cpu().detach().numpy()for item in image_list]).to(device)\n",
    "        img_list=image_list.reshape(len(image_list),512)\n",
    "        x1=torch.stack([token_list,img_list],1).to(device)\n",
    "        x1=x1.float()\n",
    "        y1=x1.reshape(num,2,1,512)\n",
    "        out1 = self.attention1(y1)\n",
    "        x2=torch.stack([token_list,text_list],1)\n",
    "        y2=x2.reshape(num,2,1,512)\n",
    "        out2 = self.attention1(y2)\n",
    "        x3=torch.stack([img_list,text_list],1)\n",
    "        y3=x3.reshape(num,2,1,512)\n",
    "        out3= self.attention1(y3)\n",
    "        z1=torch.stack([out1[:,0],out2[:,0]],1)\n",
    "        z1=z1.reshape(num,2,1,512)\n",
    "        outputs1 = self.attention2(z1)\n",
    "        z2=torch.stack([out1[:,1],out3[:,0]],1)\n",
    "        z2=z2.expand(num,2,1,512)\n",
    "        outputs2 = self.attention2(z2)\n",
    "        z3=torch.stack([out2[:,1],out3[:,1]],1)\n",
    "        z3=z3.expand(num,2,1,512)\n",
    "        outputs2 = self.attention2(z3)\n",
    "        inputs=torch.concat((outputs1,outputs2,outputs2),dim=1)\n",
    "        inputs = self.attention3(inputs)\n",
    "        outputs=self.model3(inputs)\n",
    "        return  outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (model1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (model2): CLIP(\n",
       "    (visual): VisionTransformer(\n",
       "      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): Sequential(\n",
       "          (0): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (token_embedding): Embedding(49408, 512)\n",
       "    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (attention1): CC_module(\n",
       "    (query_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (key_conv): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (value_conv): Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (softmax): Softmax(dim=3)\n",
       "  )\n",
       "  (attention2): CBAM(\n",
       "    (Cam): ChannelAttentionModul(\n",
       "      (MaxPool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc_MaxPool): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1, out_features=2, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "      (AvgPool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc_AvgPool): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1, out_features=2, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (Sam): SpatialAttentionModul(\n",
       "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (attention3): CBAM(\n",
       "    (Cam): ChannelAttentionModul(\n",
       "      (MaxPool): AdaptiveMaxPool2d(output_size=1)\n",
       "      (fc_MaxPool): Sequential(\n",
       "        (0): Linear(in_features=6, out_features=3, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=3, out_features=6, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "      (AvgPool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc_AvgPool): Sequential(\n",
       "        (0): Linear(in_features=6, out_features=3, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=3, out_features=6, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (Sam): SpatialAttentionModul(\n",
       "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (model3): MLP(\n",
       "    (fc1): Linear(in_features=3072, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model(indim=2,device=device,outdim=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625\n",
      "0.5\n",
      "0.4375\n",
      "0.625\n",
      "0.4375\n",
      "0.5625\n",
      "0.625\n",
      "0.625\n",
      "0.5\n",
      "0.4375\n",
      "0.5625\n",
      "0.5625\n",
      "0.4375\n",
      "0.5\n",
      "0.625\n",
      "0.4375\n",
      "0.8125\n",
      "0.5625\n",
      "0.625\n",
      "0.5\n",
      "0.75\n",
      "0.5625\n",
      "0.375\n",
      "0.5\n",
      "0.6875\n",
      "0.5625\n",
      "0.8125\n",
      "0.5\n",
      "0.5625\n",
      "0.75\n",
      "0.625\n",
      "0.75\n",
      "0.5\n",
      "0.6875\n",
      "0.625\n",
      "0.6875\n",
      "0.5625\n",
      "0.6875\n",
      "0.5\n",
      "0.4375\n",
      "0.4375\n",
      "0.6875\n",
      "0.5625\n",
      "0.6875\n",
      "0.8125\n",
      "0.625\n",
      "0.625\n",
      "0.5625\n",
      "0.75\n",
      "0.8125\n",
      "0.375\n",
      "0.5\n",
      "0.625\n",
      "0.5\n",
      "0.5625\n",
      "0.5625\n",
      "0.5625\n",
      "0.6875\n",
      "0.75\n",
      "0.4375\n",
      "0.5625\n",
      "0.4375\n",
      "0.75\n",
      "0.5625\n",
      "0.75\n",
      "0.25\n",
      "0.75\n",
      "0.625\n",
      "0.5\n",
      "0.5625\n",
      "0.5\n",
      "0.5\n",
      "0.375\n",
      "0.375\n",
      "0.4375\n",
      "0.75\n",
      "0.5\n",
      "0.4375\n",
      "0.375\n",
      "0.5625\n",
      "0.5625\n",
      "0.5625\n",
      "0.6875\n",
      "0.6875\n",
      "0.75\n",
      "0.625\n",
      "0.625\n",
      "0.3125\n",
      "0.3125\n",
      "0.75\n",
      "0.5\n",
      "0.5625\n",
      "0.5625\n",
      "0.5625\n",
      "0.5\n",
      "0.4375\n",
      "0.8125\n",
      "0.375\n",
      "0.6875\n",
      "0.6875\n",
      "0.5625\n",
      "0.5625\n",
      "0.6875\n",
      "0.5625\n",
      "0.5625\n",
      "0.4375\n",
      "0.5\n",
      "0.5625\n",
      "0.375\n",
      "0.5625\n",
      "0.4375\n",
      "0.5\n",
      "0.5625\n",
      "0.375\n",
      "0.625\n",
      "0.5\n",
      "0.8125\n",
      "0.75\n",
      "0.5625\n",
      "0.375\n",
      "0.5\n",
      "0.625\n",
      "0.375\n",
      "0.6875\n",
      "0.5\n",
      "0.625\n",
      "0.6875\n",
      "0.625\n",
      "0.625\n",
      "0.625\n",
      "0.375\n",
      "0.25\n",
      "0.75\n",
      "0.625\n",
      "0.5\n",
      "0.5\n",
      "0.625\n",
      "0.25\n",
      "0.5625\n",
      "0.625\n",
      "0.5625\n",
      "0.5625\n",
      "0.3125\n",
      "0.6875\n",
      "0.5625\n",
      "0.5625\n",
      "0.25\n",
      "0.5625\n",
      "0.4375\n",
      "0.4375\n",
      "0.75\n",
      "0.625\n",
      "0.5625\n",
      "0.625\n",
      "0.6875\n",
      "0.5625\n",
      "0.8125\n",
      "0.5625\n",
      "0.5625\n",
      "0.75\n",
      "0.6875\n",
      "0.5\n",
      "0.5625\n",
      "0.5625\n",
      "0.5\n",
      "0.6875\n",
      "0.6875\n",
      "0.375\n",
      "0.75\n",
      "0.5625\n",
      "0.5625\n",
      "0.5\n",
      "0.375\n",
      "0.5625\n",
      "0.8125\n",
      "0.625\n",
      "0.375\n",
      "0.4375\n",
      "0.8125\n",
      "0.6875\n",
      "0.625\n",
      "0.6875\n",
      "0.625\n",
      "0.5\n",
      "0.5625\n",
      "0.5\n",
      "0.625\n",
      "0.8125\n",
      "0.5625\n",
      "0.6875\n",
      "0.5\n",
      "0.625\n",
      "0.4375\n",
      "0.5\n",
      "0.5\n",
      "0.4375\n",
      "0.375\n",
      "0.5\n",
      "0.625\n",
      "0.8125\n",
      "0.5\n",
      "0.5\n",
      "0.5625\n",
      "0.625\n",
      "0.5625\n",
      "0.5625\n",
      "0.5\n",
      "0.75\n",
      "0.4375\n",
      "0.625\n",
      "0.5\n",
      "0.75\n",
      "0.625\n",
      "0.25\n",
      "0.5\n",
      "0.625\n",
      "0.625\n",
      "0.6875\n",
      "0.375\n",
      "0.5625\n",
      "0.5625\n",
      "0.75\n",
      "0.625\n",
      "0.625\n",
      "0.625\n",
      "0.4375\n",
      "0.5\n",
      "0.5\n",
      "0.5625\n",
      "0.625\n",
      "0.4375\n",
      "0.5625\n",
      "0.6875\n",
      "0.625\n",
      "0.5\n",
      "0.5625\n",
      "0.8125\n",
      "0.5\n",
      "0.4375\n",
      "0.6875\n",
      "0.25\n",
      "0.375\n",
      "0.5625\n",
      "0.8125\n",
      "0.625\n",
      "0.625\n",
      "0.5\n",
      "0.625\n",
      "0.5\n",
      "0.5625\n",
      "0.4375\n",
      "0.8125\n",
      "0.8125\n",
      "0.5\n",
      "0.625\n",
      "0.625\n",
      "0.75\n",
      "0.75\n",
      "0.5625\n",
      "0.625\n",
      "0.4375\n",
      "0.4375\n",
      "0.625\n",
      "0.5\n",
      "0.5625\n",
      "0.75\n",
      "0.625\n",
      "0.4375\n",
      "0.4375\n",
      "0.3125\n",
      "0.6875\n",
      "0.5625\n",
      "0.4375\n",
      "0.5\n",
      "0.3125\n",
      "0.375\n",
      "0.6875\n",
      "0.75\n",
      "0.375\n",
      "0.25\n",
      "0.6875\n",
      "0.5\n",
      "0.375\n",
      "0.5625\n",
      "0.6875\n",
      "0.5625\n",
      "0.625\n",
      "0.5625\n",
      "0.75\n",
      "0.4375\n",
      "0.5\n",
      "0.75\n",
      "0.5625\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 602112 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tang xiaoqing\\Desktop\\深度学习\\注意力\\pytorch-multimodal_sarcasm_detection-main\\a.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tang%20xiaoqing/Desktop/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B/pytorch-multimodal_sarcasm_detection-main/a.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m labels1\u001b[39m=\u001b[39mlabels_train[split\u001b[39m*\u001b[39mx:split\u001b[39m*\u001b[39m(x\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tang%20xiaoqing/Desktop/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B/pytorch-multimodal_sarcasm_detection-main/a.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m labels1\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor(labels1)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tang%20xiaoqing/Desktop/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B/pytorch-multimodal_sarcasm_detection-main/a.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m outputs \u001b[39m=\u001b[39mmodel_all(text_train[x\u001b[39m*\u001b[39;49msplit:(x\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m*\u001b[39;49msplit],token_train[x\u001b[39m*\u001b[39;49msplit:(x\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m*\u001b[39;49msplit],img_train,split,x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tang%20xiaoqing/Desktop/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B/pytorch-multimodal_sarcasm_detection-main/a.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(outputs,\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tang%20xiaoqing/Desktop/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B/pytorch-multimodal_sarcasm_detection-main/a.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs,labels1)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\tang xiaoqing\\Desktop\\深度学习\\注意力\\pytorch-multimodal_sarcasm_detection-main\\a.ipynb Cell 17\u001b[0m in \u001b[0;36mModel.forward\u001b[1;34m(self, text, token, img, num, count)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tang%20xiaoqing/Desktop/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B/pytorch-multimodal_sarcasm_detection-main/a.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(b):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tang%20xiaoqing/Desktop/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B/pytorch-multimodal_sarcasm_detection-main/a.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     a\u001b[39m=\u001b[39mImage\u001b[39m.\u001b[39mopen(b)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tang%20xiaoqing/Desktop/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B/pytorch-multimodal_sarcasm_detection-main/a.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     image \u001b[39m=\u001b[39m preprocess(a)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tang%20xiaoqing/Desktop/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B/pytorch-multimodal_sarcasm_detection-main/a.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     image_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel2\u001b[39m.\u001b[39mencode_image(image)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tang%20xiaoqing/Desktop/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B/pytorch-multimodal_sarcasm_detection-main/a.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     image_list\u001b[39m.\u001b[39mappend(image_features)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 94\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    127\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    170\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n\u001b[0;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 602112 bytes."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score\n",
    "loss_fn=torch.nn.CrossEntropyLoss()\n",
    "model_all=Model(indim=2,device=device,outdim=6)\n",
    "optimizer = torch.optim.SGD(model_all.parameters(), lr=0.01,momentum=0.9)\n",
    "loss_train=[]\n",
    "loss_test=[]\n",
    "pres=[]\n",
    "recalls=[]\n",
    "avcs=[]\n",
    "f1s=[]\n",
    "avcs_train=[]\n",
    "split=16\n",
    "for j in range(3):\n",
    "        for x in range(len(train_set)//split):\n",
    "                labels1=labels_train[split*x:split*(x+1)]\n",
    "                labels1=torch.tensor(labels1).to(device)\n",
    "                outputs =model_all(text_train[x*split:(x+1)*split],token_train[x*split:(x+1)*split],img_train,split,x)\n",
    "                pred = torch.argmax(outputs,1)\n",
    "                loss = loss_fn(outputs,labels1)\n",
    "                loss_train.append(loss)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()                \n",
    "                optimizer.step()\n",
    "                pred=pred.cpu()\n",
    "                labels1=labels1.cpu()\n",
    "                avcs_train.append(accuracy_score(labels1,pred))\n",
    "                print(accuracy_score(labels1,pred))\n",
    "torch.save(model_all,'MODEL.pt')\n",
    "model_all= torch.load('MODEL.pt')\n",
    "model_all.eval()\n",
    "with torch.no_grad():\n",
    "        for h in range(len(test_set)//split):\n",
    "                labels2=labels_test[h*split:(h+1)*split]\n",
    "                labels2=torch.tensor(labels2).to(device)\n",
    "                outputs =model_all(text_test[h*split:(h+1)*split],token_test[h*split:(h+1)*split],img_test,split,h)\n",
    "                pred = torch.argmax(outputs,1)\n",
    "                loss = loss_fn(outputs,labels2)\n",
    "                loss_test.append(loss)\n",
    "                labels2=labels2.cpu()\n",
    "                pred=pred.cpu()\n",
    "                f1s.append(f1_score(labels2,pred))\n",
    "                pres.append(precision_score(labels2,pred))\n",
    "                recalls.append(recall_score(labels2,pred))\n",
    "                avcs.append(accuracy_score(labels2,pred))\n",
    "print(np.mean(pres),np.mean(recalls),np.mean(recalls),np.mean(avcs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ebf9cfd872009544a161647ac82c48f4cc096aba58631b69e515c7576d66293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
