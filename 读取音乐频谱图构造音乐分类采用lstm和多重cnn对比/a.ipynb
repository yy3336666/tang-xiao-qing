{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 使用 StandardScaler 进行标准化\n",
    "scaler = StandardScaler()\n",
    "def preprocess_data(data_path):\n",
    "    genres = os.listdir(data_path)\n",
    "    features = []\n",
    "    labels = []\n",
    "    for genre_id, genre in enumerate(genres):\n",
    "        genre_path = os.path.join(data_path, genre)\n",
    "        for file_name in os.listdir(genre_path):\n",
    "            file_path = os.path.join(genre_path, file_name)\n",
    "            if file_path!='Data/genres_original\\jazz\\jazz.00054.wav':\n",
    "            # 加载音频文件并提取 MEL 频谱特征\n",
    "                y, sr = librosa.load(file_path, sr=None)\n",
    "                mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
    "                mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "                scaled_data = scaler.fit_transform(mel_spectrogram)\n",
    "                # 将特征添加到特征列表中\n",
    "                features.append(scaled_data)\n",
    "                labels.append(genre_id)\n",
    "    return features, labels\n",
    "\n",
    "data_path = 'Data/genres_original'\n",
    "preprocessed_data, labels = preprocess_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 647)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)\n",
    "preprocessed_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "label=[]\n",
    "for i in range(len(preprocessed_data)):\n",
    "    if preprocessed_data[i].shape==(128, 647):\n",
    "        data.append(preprocessed_data[i])\n",
    "        label.append(labels[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "class GTZANDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "\n",
    "dataset = GTZANDataset(data, labels)\n",
    "\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "batch_size=128\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class GenreLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes,dropout_rate):\n",
    "        super(GenreLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "       \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "num_classes=10\n",
    "num_layers=1\n",
    "hidden_size=128\n",
    "input_size=647\n",
    "dropout_rate = 0.5\n",
    "model =GenreLSTM(input_size, hidden_size, num_layers, num_classes,dropout_rate=dropout_rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 2.3113, Validation Loss: 2.2803\n",
      "Epoch [2/100], Train Loss: 2.2746, Validation Loss: 2.2573\n",
      "Epoch [3/100], Train Loss: 2.2744, Validation Loss: 2.2567\n",
      "Epoch [4/100], Train Loss: 2.2463, Validation Loss: 2.2661\n",
      "Epoch [5/100], Train Loss: 2.2393, Validation Loss: 2.2442\n",
      "Epoch [6/100], Train Loss: 2.2617, Validation Loss: 2.2549\n",
      "Epoch [7/100], Train Loss: 2.2350, Validation Loss: 2.2287\n",
      "Epoch [8/100], Train Loss: 2.2200, Validation Loss: 2.2306\n",
      "Epoch [9/100], Train Loss: 2.2071, Validation Loss: 2.2354\n",
      "Epoch [10/100], Train Loss: 2.1952, Validation Loss: 2.2241\n",
      "Epoch [11/100], Train Loss: 2.1811, Validation Loss: 2.2384\n",
      "Epoch [12/100], Train Loss: 2.1771, Validation Loss: 2.2091\n",
      "Epoch [13/100], Train Loss: 2.1728, Validation Loss: 2.2068\n",
      "Epoch [14/100], Train Loss: 2.1317, Validation Loss: 2.1880\n",
      "Epoch [15/100], Train Loss: 2.1493, Validation Loss: 2.1793\n",
      "Epoch [16/100], Train Loss: 2.1520, Validation Loss: 2.1918\n",
      "Epoch [17/100], Train Loss: 2.0989, Validation Loss: 2.2020\n",
      "Epoch [18/100], Train Loss: 2.0404, Validation Loss: 2.2004\n",
      "Epoch [19/100], Train Loss: 2.1074, Validation Loss: 2.1881\n",
      "Epoch [20/100], Train Loss: 2.0321, Validation Loss: 2.2000\n",
      "Epoch [21/100], Train Loss: 2.0880, Validation Loss: 2.1763\n",
      "Epoch [22/100], Train Loss: 2.0291, Validation Loss: 2.1585\n",
      "Epoch [23/100], Train Loss: 2.0257, Validation Loss: 2.1421\n",
      "Epoch [24/100], Train Loss: 2.0049, Validation Loss: 2.1495\n",
      "Epoch [25/100], Train Loss: 1.9802, Validation Loss: 2.1558\n",
      "Epoch [26/100], Train Loss: 1.9303, Validation Loss: 2.2091\n",
      "Epoch [27/100], Train Loss: 1.9213, Validation Loss: 2.1928\n",
      "Epoch [28/100], Train Loss: 1.9072, Validation Loss: 2.2351\n",
      "Epoch [29/100], Train Loss: 1.9488, Validation Loss: 2.2081\n",
      "Epoch [30/100], Train Loss: 1.9578, Validation Loss: 2.1824\n",
      "Epoch [31/100], Train Loss: 1.8042, Validation Loss: 2.1708\n",
      "Epoch [32/100], Train Loss: 1.7955, Validation Loss: 2.1957\n",
      "Epoch [33/100], Train Loss: 1.8532, Validation Loss: 2.2337\n",
      "Epoch [34/100], Train Loss: 1.8262, Validation Loss: 2.1803\n",
      "Epoch [35/100], Train Loss: 1.7849, Validation Loss: 2.2252\n",
      "Epoch [36/100], Train Loss: 1.7555, Validation Loss: 2.2012\n",
      "Epoch [37/100], Train Loss: 1.7195, Validation Loss: 2.2020\n",
      "Epoch [38/100], Train Loss: 1.7195, Validation Loss: 2.1642\n",
      "Epoch [39/100], Train Loss: 1.6652, Validation Loss: 2.1723\n",
      "Epoch [40/100], Train Loss: 1.5682, Validation Loss: 2.1922\n",
      "Epoch [41/100], Train Loss: 1.5182, Validation Loss: 2.2609\n",
      "Epoch [42/100], Train Loss: 1.5378, Validation Loss: 2.2192\n",
      "Epoch [43/100], Train Loss: 1.4687, Validation Loss: 2.2397\n",
      "Epoch [44/100], Train Loss: 1.4217, Validation Loss: 2.2873\n",
      "Epoch [45/100], Train Loss: 1.3873, Validation Loss: 2.2844\n",
      "Epoch [46/100], Train Loss: 1.3259, Validation Loss: 2.2812\n",
      "Epoch [47/100], Train Loss: 1.3028, Validation Loss: 2.3575\n",
      "Epoch [48/100], Train Loss: 1.2773, Validation Loss: 2.4440\n",
      "Epoch [49/100], Train Loss: 1.2311, Validation Loss: 2.4837\n",
      "Epoch [50/100], Train Loss: 1.2306, Validation Loss: 2.3738\n",
      "Epoch [51/100], Train Loss: 1.2007, Validation Loss: 2.4586\n",
      "Epoch [52/100], Train Loss: 1.1326, Validation Loss: 2.4093\n",
      "Epoch [53/100], Train Loss: 1.1691, Validation Loss: 2.4094\n",
      "Epoch [54/100], Train Loss: 1.1006, Validation Loss: 2.5123\n",
      "Epoch [55/100], Train Loss: 0.9821, Validation Loss: 2.4167\n",
      "Epoch [56/100], Train Loss: 1.0144, Validation Loss: 2.4164\n",
      "Epoch [57/100], Train Loss: 0.9739, Validation Loss: 2.5290\n",
      "Epoch [58/100], Train Loss: 1.0670, Validation Loss: 2.4645\n",
      "Epoch [59/100], Train Loss: 1.0455, Validation Loss: 2.4263\n",
      "Epoch [60/100], Train Loss: 0.9583, Validation Loss: 2.4474\n",
      "Epoch [61/100], Train Loss: 0.9372, Validation Loss: 2.5351\n",
      "Epoch [62/100], Train Loss: 0.8599, Validation Loss: 2.6502\n",
      "Epoch [63/100], Train Loss: 0.8683, Validation Loss: 2.5828\n",
      "Epoch [64/100], Train Loss: 0.7656, Validation Loss: 2.7216\n",
      "Epoch [65/100], Train Loss: 0.7989, Validation Loss: 2.8107\n",
      "Epoch [66/100], Train Loss: 0.7529, Validation Loss: 2.7495\n",
      "Epoch [67/100], Train Loss: 0.7007, Validation Loss: 2.7493\n",
      "Epoch [68/100], Train Loss: 0.6949, Validation Loss: 2.7722\n",
      "Epoch [69/100], Train Loss: 0.6480, Validation Loss: 2.8706\n",
      "Epoch [70/100], Train Loss: 0.5922, Validation Loss: 2.8375\n",
      "Epoch [71/100], Train Loss: 0.5971, Validation Loss: 2.8619\n",
      "Epoch [72/100], Train Loss: 0.5635, Validation Loss: 2.7889\n",
      "Epoch [73/100], Train Loss: 0.5609, Validation Loss: 2.8114\n",
      "Epoch [74/100], Train Loss: 0.5690, Validation Loss: 2.8027\n",
      "Epoch [75/100], Train Loss: 0.4831, Validation Loss: 2.9178\n",
      "Epoch [76/100], Train Loss: 0.4608, Validation Loss: 2.9263\n",
      "Epoch [77/100], Train Loss: 0.4455, Validation Loss: 3.0488\n",
      "Epoch [78/100], Train Loss: 0.4363, Validation Loss: 3.0754\n",
      "Epoch [79/100], Train Loss: 0.4095, Validation Loss: 3.1012\n",
      "Epoch [80/100], Train Loss: 0.4655, Validation Loss: 3.2249\n",
      "Epoch [81/100], Train Loss: 0.4077, Validation Loss: 3.1608\n",
      "Epoch [82/100], Train Loss: 0.3587, Validation Loss: 3.2457\n",
      "Epoch [83/100], Train Loss: 0.3854, Validation Loss: 3.1071\n",
      "Epoch [84/100], Train Loss: 0.3228, Validation Loss: 3.1772\n",
      "Epoch [85/100], Train Loss: 0.2991, Validation Loss: 3.2909\n",
      "Epoch [86/100], Train Loss: 0.2820, Validation Loss: 3.2835\n",
      "Epoch [87/100], Train Loss: 0.3036, Validation Loss: 3.2932\n",
      "Epoch [88/100], Train Loss: 0.2501, Validation Loss: 3.4474\n",
      "Epoch [89/100], Train Loss: 0.2257, Validation Loss: 3.5828\n",
      "Epoch [90/100], Train Loss: 0.2296, Validation Loss: 3.5165\n",
      "Epoch [91/100], Train Loss: 0.2016, Validation Loss: 3.5512\n",
      "Epoch [92/100], Train Loss: 0.2316, Validation Loss: 3.7716\n",
      "Epoch [93/100], Train Loss: 0.2701, Validation Loss: 3.7107\n",
      "Epoch [94/100], Train Loss: 0.3129, Validation Loss: 3.3956\n",
      "Epoch [95/100], Train Loss: 0.2737, Validation Loss: 3.5372\n",
      "Epoch [96/100], Train Loss: 0.2608, Validation Loss: 3.6718\n",
      "Epoch [97/100], Train Loss: 0.2345, Validation Loss: 3.4804\n",
      "Epoch [98/100], Train Loss: 0.2003, Validation Loss: 3.8443\n",
      "Epoch [99/100], Train Loss: 0.2490, Validation Loss: 3.7729\n",
      "Epoch [100/100], Train Loss: 0.2267, Validation Loss: 3.7799\n",
      "Test Accuracy: 19.79%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "   \n",
    "    model.train()\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(data)\n",
    "        labels = labels.long()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "   \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, labels in val_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            labels = labels.long()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, labels in test_loader:\n",
    "        \n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(data)\n",
    "        labels = labels.long()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Test Accuracy: {:.2f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Discriminator Loss: 0.010071410797536373, Generator Loss: 4.750080108642578\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = Generator(input_size, hidden_size, num_layers, input_size).to(device)\n",
    "discriminator = Discriminator(input_size, hidden_size, num_layers, 1).to(device)\n",
    "\n",
    "\n",
    "criterion_gan = nn.BCELoss()\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=1e-3)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        \n",
    "       \n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_labels = torch.ones(data.size(0), 1).to(device)\n",
    "        fake_labels = torch.zeros(data.size(0), 1).to(device)\n",
    "\n",
    "        real_outputs = discriminator(data)\n",
    "        real_loss = criterion_gan(real_outputs, real_labels)\n",
    "        noise = torch.randn(data.size(0),data.size(1), input_size).to(device)\n",
    "        fake_data = generator(noise)\n",
    "        fake_outputs = discriminator(fake_data)\n",
    "        fake_loss = criterion_gan(fake_outputs, fake_labels)\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "      \n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        noise = torch.randn(data.size(0), data.size(1), input_size).to(device)\n",
    "        fake_data = generator(noise)\n",
    "        fake_outputs = discriminator(fake_data)\n",
    "\n",
    "        g_loss = criterion_gan(fake_outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "print(f'Epoch [{epoch+1}/{num_epochs}], Discriminator Loss: {d_loss.item()}, Generator Loss: {g_loss.item()}')\n",
    "noise = torch.randn(len(train_dataset), data.size(1), input_size).to(device)\n",
    "generated_data = generator(noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32278854,  0.3272677 , -0.09516631, ...,  1.4742877 ,\n",
       "        -0.5396615 , -0.39885685],\n",
       "       [ 0.6430355 ,  0.19385163, -0.19499926, ...,  1.5642091 ,\n",
       "        -0.26930186, -0.3093978 ],\n",
       "       [ 0.60352606,  0.31450683, -0.0623032 , ...,  1.8034525 ,\n",
       "        -0.70429707, -0.32490927],\n",
       "       ...,\n",
       "       [ 0.33393404,  0.00804125, -0.22638065, ...,  1.8626825 ,\n",
       "        -0.44945222, -0.35803303],\n",
       "       [ 0.95635974,  0.47882026, -0.09175487, ...,  1.6892006 ,\n",
       "        -0.3957002 , -0.46639317],\n",
       "       [ 0.4624194 ,  0.55562466,  0.22877781, ...,  1.6736945 ,\n",
       "        -0.47752613, -0.33423373]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "num_classes = 10\n",
    "num_audios_per_class = 66\n",
    "fake_data_np = generated_data.detach().cpu().numpy()\n",
    "fake_data_np = fake_data_np.reshape(660,-1)\n",
    "output_dir = \"generated_audios\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "sample_rate = 22050\n",
    "\n",
    "for class_idx in range(num_classes):\n",
    "    class_dir = os.path.join(output_dir, f\"class_{class_idx}\")\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "    for audio_idx in range(num_audios_per_class):\n",
    "        fake_data_np1 = fake_data_np[class_idx*audio_idx,:]\n",
    "        fake_data_np1 = fake_data_np1 * 32768\n",
    "        fake_data_np1 = fake_data_np1.astype(np.int16)\n",
    "\n",
    "        output_file = os.path.join(class_dir, f\"audio_{audio_idx}.wav\")\n",
    "        sf.write(output_file, fake_data_np1, sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
